# 名词解释

信息熵

- 接收的每條消息中包含的信息的平均量；
- 描述信源的不确定度；越隨機的信源的熵越大。

条件熵

- 在一个条件下，随机变量的不确定性。

信息增益

- 熵 - 条件熵。表示在一个条件下，信息不确定性减少的程度。

分类器

- 分类器是数据挖掘中对样本进行分类的方法的统称，包含决策树、逻辑回归、朴素贝叶斯、神经网络等算法。

过学习现象

- 过学习（overfitting）问题是指学习机器的训练误差过小，反而导致泛化能力下降，这是由于学习样本不充分以及学习机器设计不合理而引起的。overfitting，即过度拟合。
- 学习能力强，超出了实际问题的需要；
- 样本过少，各类样本数量不平衡；甚至将样本中的噪声都学习到。

泛化

- 模型在訓練集的表現佳，但在測試集（即從未見過的數據）可能表現極差，表示此模型沒有足夠泛化（generalization）
- [机器学习算法](https://baike.baidu.com/item/机器学习算法/18635836)对新鲜样本的适应能力；学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的网络也能给出合适的输出

剪枝

- 减除决策树中意义不大的节点来从而减小决策树的大小。剪枝算法可以有效缓解过拟合问题。

- 预剪枝是在决策树生成过程中，对树进行剪枝，提前结束树的分支生长。
- 后剪枝是在决策树生长完成之后，对树进行剪枝，得到简化版的决策树。

奥卡姆的剃刀

- 簡約法則
- 如果關於同一個問題有許多種[理論](https://www.wikiwand.com/zh-hk/理论)，每一種都能作出同樣準確的[預言](https://www.wikiwand.com/zh-hk/预言)，那麼應該挑選其中使用假定最少的。儘管越複雜的方法通常能做出越好的預言，但是在不考慮預言能力（即結果大致相同）的情況下，假設越少越好。

反向传播算法

- 反向传播（英语：Backpropagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法

感知机

- 可以被视为一种最简单形式的前馈神经网络，是一种二元线性分类器。
- 输入是实例的特征向量，输出是用“+1”和“-1”表示的实例类别。作为判别模型，感知机将实例用一个超平面划分为正负两类，是神经网络和支持向量机的基础。

激励函数

- 神经网络中的每个节点接受输入值，并将输入值传递给下一层，输入节点会将输入属性值直接传递给下一层（隐层或输出层）。在神经网络中，隐层和输出层节点的输入和输出之间具有函数关系，这个函数称为激励函数。

前馈神经网络（FNN）

- 各神经元可以接收前一层神经元的信号，并产生输出到下一层。第0层叫**输入层**，最后一层叫**输出层**，其他中间层叫做隐含层（或隐藏层、隐层）。隐层可以是一层。也可以是多层 。
- 整个网络中无反馈，信号从输入层向输出层**单向传播**，可用一个有向无环图表示。
- 适用于：训练样本含有噪声；需要较快的测试相应速度；多分类问题。
